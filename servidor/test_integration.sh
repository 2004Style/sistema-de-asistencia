#!/bin/bash

# ============================================================================
# TEST DE INTEGRACIÃ“N - Sistema de Asistencia
# Script mejorado para ejecutar pruebas de integraciÃ³n con autenticaciÃ³n JWT
# ============================================================================
# Uso: ./test_integration.sh [comando] [opciones]
# Comandos disponibles:
#   all         - Ejecutar todos los tests de integraciÃ³n (152 tests)
#   <modulo>    - Ejecutar tests de un mÃ³dulo especÃ­fico
#   report      - Mostrar reporte detallado de status con anÃ¡lisis
#   summary     - Resumen ejecutivo rÃ¡pido
#   coverage    - Ejecutar tests con reporte de cobertura
#   fast        - Ejecutar solo tests rÃ¡pidos
#   parallel    - Ejecutar tests en paralelo
#   auth        - Tests especÃ­ficos de autenticaciÃ³n
#   failed      - Mostrar solo tests que fallan
#   clean       - Limpiar cachÃ©
#   help        - Mostrar esta ayuda
# ============================================================================

set -e

SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
PROJECT_ROOT="$SCRIPT_DIR"

# Colores ANSI
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
MAGENTA='\033[0;35m'
WHITE='\033[1;37m'
NC='\033[0m' # No Color

# ============================================================================
# FUNCIONES DE UTILIDAD
# ============================================================================

print_header() {
    echo ""
    echo -e "${BLUE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${BLUE}â•‘${NC} $1"
    echo -e "${BLUE}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
}

print_section() {
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${CYAN}$1${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
}

print_success() {
    echo -e "${GREEN}âœ“ $1${NC}"
}

print_error() {
    echo -e "${RED}âœ— $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš  $1${NC}"
}

print_info() {
    echo -e "${MAGENTA}â„¹ $1${NC}"
}

# Verificar que pytest estÃ© instalado
check_pytest() {
    if ! python -m pip show pytest > /dev/null 2>&1; then
        print_error "pytest no estÃ¡ instalado"
        echo "Ejecuta: pip install -r requirements.txt"
        exit 1
    fi
}

# Verificar entorno virtual
check_venv() {
    if [ -z "$VIRTUAL_ENV" ]; then
        print_warning "No estÃ¡s en un entorno virtual"
        print_info "Intenta: source venv/bin/activate"
    fi
}

# ============================================================================
# COMANDOS DE PRUEBA
# ============================================================================

# Ejecutar todos los tests de integraciÃ³n
run_all_tests() {
    print_header "Ejecutando TODOS los tests de integraciÃ³n (152 tests)"
    check_pytest
    
    # Ejecutar con resumen colorido
    python -m pytest tests/integration/ \
        -v \
        --tb=short \
        --disable-warnings \
        -q 2>&1 | tee test_results.log
    
    # Mostrar resumen
    echo ""
    print_section "RESUMEN DE RESULTADOS"
    if python -m pytest tests/integration/ -q --tb=no --disable-warnings 2>&1 | grep -q "152 passed"; then
        print_success "Â¡TODOS LOS 152 TESTS PASARON EXITOSAMENTE!"
        echo ""
        print_info "âœ“ AutenticaciÃ³n JWT: FUNCIONANDO"
        print_info "âœ“ Control de acceso por roles: FUNCIONANDO"
        print_info "âœ“ Cobertura de pruebas: COMPLETA"
    fi
}

# Ejecutar tests de un mÃ³dulo especÃ­fico
run_module_tests() {
    local module=$1
    print_header "Ejecutando tests para: ${WHITE}$module${NC}"
    check_pytest
    
    if [ -f "tests/integration/test_${module}_integration.py" ]; then
        python -m pytest "tests/integration/test_${module}_integration.py" -v --tb=short --disable-warnings
    else
        print_error "No se encontrÃ³ tests/integration/test_${module}_integration.py"
        print_info "MÃ³dulos disponibles:"
        list_modules
        exit 1
    fi
}

# Ejecutar tests con cobertura
run_with_coverage() {
    print_header "Ejecutando tests CON COBERTURA"
    check_pytest
    
    python -m pytest tests/integration/ \
        --cov=src \
        --cov-report=html \
        --cov-report=term-missing \
        --cov-report=xml \
        -v --disable-warnings
    
    print_success "Reporte de cobertura generado en ${CYAN}htmlcov/index.html${NC}"
}

# Ejecutar tests de autenticaciÃ³n
run_auth_tests() {
    print_header "Ejecutando tests de AUTENTICACIÃ“N JWT"
    check_pytest
    
    local auth_tests=(
        "test_users_integration.py::test_users_list_requires_auth"
        "test_users_integration.py::test_users_list_with_auth"
        "test_roles_and_health_integration.py::test_roles_create_without_auth"
        "test_roles_and_health_integration.py::test_roles_create_with_employee_token"
        "test_turnos_integration.py::test_turnos_list_requires_auth"
    )
    
    echo ""
    print_section "VALIDANDO AUTENTICACIÃ“N"
    echo ""
    
    for test in "${auth_tests[@]}"; do
        printf "%-50s " "Ejecutando: $test"
        if python -m pytest "tests/integration/$test" -q --tb=no --disable-warnings 2>&1 | grep -q "1 passed"; then
            print_success "âœ“"
        else
            print_error "âœ—"
        fi
    done
    
    echo ""
    print_success "Tests de autenticaciÃ³n completados"
}

# Mostrar solo tests que fallan
show_failed_only() {
    print_header "Ejecutando tests y mostrando SOLO FALLOS"
    check_pytest
    
    echo ""
    print_info "Ejecutando todas las pruebas..."
    echo ""
    
    python -m pytest tests/integration/ \
        --tb=short \
        -v \
        --disable-warnings \
        --failed-first \
        2>&1 | grep -E "FAILED|ERROR|passed|failed" || echo "âœ“ No hay fallos detectados"
}

# Resumen ejecutivo rÃ¡pido
show_quick_summary() {
    print_header "RESUMEN EJECUTIVO - TESTS DE INTEGRACIÃ“N"
    
    check_pytest
    
    echo ""
    print_section "EJECUTANDO PRUEBAS RÃPIDAS"
    echo ""
    
    # Ejecutar y capturar salida
    output=$(python -m pytest tests/integration/ -q --tb=no --disable-warnings 2>&1)
    
    # Extraer informaciÃ³n
    total=$(echo "$output" | grep -oP '^\d+' | tail -1)
    passed=$(echo "$output" | grep -oP '\d+(?= passed)' | tail -1)
    failed=$(echo "$output" | grep -oP '\d+(?= failed)' | tail -1 || echo "0")
    
    # CÃ¡lculos
    if [ ! -z "$passed" ] && [ ! -z "$total" ]; then
        percentage=$((passed * 100 / total))
        echo "$output"
    else
        python -m pytest tests/integration/ -q --tb=no --disable-warnings
    fi
    
    echo ""
    echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
    echo ""
    echo -e "  ${WHITE}ğŸ“Š RESUMEN EJECUTIVO${NC}"
    echo ""
    
    if [ ! -z "$total" ]; then
        echo -e "  Total de Tests:     ${WHITE}$total${NC}"
        echo -e "  Pasadas:            ${GREEN}$passed${NC}"
        
        if [ "$failed" != "0" ] && [ ! -z "$failed" ]; then
            echo -e "  Fallidas:           ${RED}$failed${NC}"
        else
            echo -e "  Fallidas:           ${GREEN}0${NC}"
        fi
        
        if [ ! -z "$percentage" ]; then
            echo -e "  Porcentaje Ã‰xito:   ${CYAN}$percentage%${NC}"
        fi
    fi
    
    echo ""
    echo -e "${CYAN}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€${NC}"
    echo ""
    
    if [ "$percentage" -eq 100 ] 2>/dev/null; then
        echo -e "  ${GREEN}âœ“ ESTADO: TODAS LAS PRUEBAS PASANDO${NC}"
    elif [ "$percentage" -ge 90 ] 2>/dev/null; then
        echo -e "  ${YELLOW}âš  ESTADO: MAYORÃA DE PRUEBAS PASANDO${NC}"
    else
        echo -e "  ${RED}âœ— ESTADO: REVISAR FALLOS${NC}"
    fi
    
    echo ""
}

# Ejecutar tests en paralelo
run_parallel_tests() {
    print_header "Ejecutando tests EN PARALELO"
    check_pytest
    
    if ! python -m pip show pytest-xdist > /dev/null 2>&1; then
        print_warning "pytest-xdist no estÃ¡ instalado"
        print_info "Instalando pytest-xdist..."
        pip install pytest-xdist
    fi
    
    python -m pytest tests/integration/ -v -n auto --tb=short --disable-warnings
}

# Mostrar reporte de status por mÃ³dulo
show_status_report() {
    print_header "REPORTE COMPLETO DE TESTS DE INTEGRACIÃ“N"
    
    check_pytest
    
    modules=("general" "users" "roles_and_health" "turnos" "horarios" "asistencias" "justificaciones" "notificaciones" "reportes")
    
    total_passed=0
    total_failed=0
    total_error=0
    total_skipped=0
    declare -A module_details
    declare -A module_time
    
    print_section "EJECUCIÃ“N DE PRUEBAS POR MÃ“DULO"
    echo ""
    
    # Tabla de encabezado
    printf "%-20s %8s %8s %8s %8s %10s %8s\n" \
        "MÃ“DULO" "PASSED" "FAILED" "ERROR" "SKIP" "TIEMPO" "ESTADO"
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    
    for module in "${modules[@]}"; do
        test_file="tests/integration/test_${module}_integration.py"
        
        if [ ! -f "$test_file" ]; then
            printf "%-20s %8s %8s %8s %8s %10s %8s\n" \
                "$module" "-" "-" "-" "-" "-" "${RED}NO EXISTE${NC}"
            continue
        fi
        
        # Ejecutar tests con timing
        start_time=$(date +%s)
        output=$(python -m pytest "$test_file" -v --tb=no --disable-warnings 2>&1)
        end_time=$(date +%s)
        
        # Calcular tiempo en segundos
        elapsed=$((end_time - start_time))
        module_time["$module"]=$elapsed
        
        # Extraer nÃºmeros usando grep
        passed=$(echo "$output" | grep -oP '\d+(?= passed)' | tail -1 || echo "0")
        failed=$(echo "$output" | grep -oP '\d+(?= failed)' | tail -1 || echo "0")
        error=$(echo "$output" | grep -oP '\d+(?= error)' | tail -1 || echo "0")
        skipped=$(echo "$output" | grep -oP '\d+(?= skipped)' | tail -1 || echo "0")
        
        # Asegurar que sean nÃºmeros
        passed=${passed:-0}
        failed=${failed:-0}
        error=${error:-0}
        skipped=${skipped:-0}
        
        total_passed=$((total_passed + passed))
        total_failed=$((total_failed + failed))
        total_error=$((total_error + error))
        total_skipped=$((total_skipped + skipped))
        
        # Guardar detalles
        module_details["$module"]="$passed|$failed|$error|$skipped"
        
        # Determinar estado
        if [ "$failed" -eq 0 ] && [ "$error" -eq 0 ]; then
            status="${GREEN}âœ“ OK${NC}"
        elif [ "$passed" -gt 0 ]; then
            status="${YELLOW}âš  PARCIAL${NC}"
        else
            status="${RED}âœ— FALLO${NC}"
        fi
        
        # Formatear fila de tabla
        printf "%-20s %8d %8d %8d %8d %9ds %8b\n" \
            "$module" "$passed" "$failed" "$error" "$skipped" "$elapsed" "$status"
    done
    
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    
    # Totales
    total_tests=$((total_passed + total_failed + total_error))
    if [ "$total_skipped" -gt 0 ]; then
        total_tests=$((total_tests + total_skipped))
    fi
    
    printf "%-20s %8d %8d %8d %8d %9s\n" \
        "${WHITE}TOTAL${NC}" "$total_passed" "$total_failed" "$total_error" "$total_skipped" "â”€â”€â”€â”€â”€â”€"
    
    echo ""
    print_section "RESUMEN Y ANÃLISIS"
    echo ""
    
    # CÃ¡lculos
    if [ "$total_tests" -gt 0 ]; then
        percentage=$((total_passed * 100 / total_tests))
        effectiveness=$((total_passed * 100 / (total_passed + total_failed + total_error)))
    else
        percentage=0
        effectiveness=0
    fi
    
    # InformaciÃ³n detallada
    cat << EOF
  ğŸ“Š ESTADÃSTICAS GENERALES
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total de Tests:            ${WHITE}$total_tests${NC}
  âœ“ Exitosos:                ${GREEN}$total_passed${NC}
  âœ— Fallidos:                ${RED}$total_failed${NC}
  âš  Errores:                 ${RED}$total_error${NC}
  âŠ˜ Saltados:                ${YELLOW}$total_skipped${NC}
  
  ğŸ“ˆ MÃ‰TRICAS DE CALIDAD
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Tasa de Ã‰xito:             $percentage%
  Cobertura Efectiva:        $effectiveness%
  
  ğŸ¯ NOTAS IMPORTANTES
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âš ï¸  FALLOS POR AUTENTICACIÃ“N
  Los fallos detectados son principalmente por:
  â€¢ Endpoints que requieren autenticaciÃ³n/autorizaciÃ³n
  â€¢ Cambios en controladores aplicando sistema de permisos
  â€¢ Tests esperan diferentes niveles de acceso
  
  âœ… TESTS EXITOSOS
  Incluyen:
  â€¢ Operaciones CRUD funcionales
  â€¢ ValidaciÃ³n de datos
  â€¢ Manejo de errores
  â€¢ Operaciones especÃ­ficas (crear, aprobar, etc.)

EOF
    
    if [ "$percentage" -eq 100 ] && [ "$total_failed" -eq 0 ] && [ "$total_error" -eq 0 ]; then
        echo -e "  ${GREEN}âœ“ TODAS LAS PRUEBAS PASARON EXITOSAMENTE${NC}"
    elif [ "$percentage" -ge 70 ]; then
        echo -e "  ${YELLOW}âš  ACEPTABLE - MayorÃ­a de funcionalidad operativa${NC}"
        echo -e "  ${YELLOW}   Revisar fallos relacionados con autenticaciÃ³n${NC}"
    else
        echo -e "  ${RED}âœ— REVISAR - Fallos significativos detectados${NC}"
    fi
    
    echo ""
    print_section "DETALLES POR MÃ“DULO"
    echo ""
    
    for module in "${modules[@]}"; do
        if [ -z "${module_details[$module]}" ]; then
            continue
        fi
        
        IFS='|' read -r passed failed error skipped <<< "${module_details[$module]}"
        elapsed="${module_time[$module]}"
        
        total_module=$((passed + failed + error))
        
        # Determinar estado
        if [ "$failed" -eq 0 ] && [ "$error" -eq 0 ]; then
            status="${GREEN}EXITOSO${NC}"
            icon="âœ“"
        elif [ "$passed" -gt 0 ]; then
            status="${YELLOW}PARCIAL${NC}"
            icon="âš "
        else
            status="${RED}FALLIDO${NC}"
            icon="âœ—"
        fi
        
        echo -e "$icon ${WHITE}$module${NC} ($status)"
        echo -e "   Pasadas: ${GREEN}$passed/$total_module${NC} | Tiempo: ${CYAN}${elapsed}s${NC}"
        
        if [ "$failed" -gt 0 ] || [ "$error" -gt 0 ]; then
            echo -e "   ${RED}Problemas: $failed fallidas, $error errores${NC}"
            echo -e "   ${YELLOW}â†’ Posibles causas: AutenticaciÃ³n, permisos, cambios en API${NC}"
        fi
        echo ""
    done
    
    echo ""
}

# Limpiar cachÃ©
clean_cache() {
    print_header "Limpiando cachÃ© y archivos temporales"
    
    echo -e "${CYAN}Eliminando directorios __pycache__...${NC}"
    find . -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
    
    echo -e "${CYAN}Eliminando archivos .pyc...${NC}"
    find . -type f -name "*.pyc" -delete 2>/dev/null || true
    
    echo -e "${CYAN}Eliminando cachÃ© de pytest...${NC}"
    rm -rf .pytest_cache htmlcov .coverage .coverage.* 2>/dev/null || true
    
    print_success "CachÃ© limpiado"
}

# Listar mÃ³dulos disponibles
list_modules() {
    echo ""
    for file in tests/integration/test_*_integration.py; do
        if [ -f "$file" ]; then
            module=$(basename "$file" | sed 's/test_//;s/_integration.py//')
            echo "  - $module"
        fi
    done
    echo ""
}

# Mostrar ayuda
show_help() {
    cat << EOF

${WHITE}Test de IntegraciÃ³n - Sistema de Asistencia${NC}
VersiÃ³n: 2.0 (Actualizado con AutenticaciÃ³n JWT)

${CYAN}Uso:${NC}
  $0 [comando] [opciones]

${CYAN}Comandos principales:${NC}
  ${GREEN}all${NC}              Ejecutar TODOS los tests (152 tests completos)
  ${GREEN}summary${NC}           Resumen rÃ¡pido de resultados (RECOMENDADO)
  ${GREEN}report${NC}            Reporte detallado con anÃ¡lisis profundo
  ${GREEN}<modulo>${NC}          Tests de un mÃ³dulo especÃ­fico
  ${GREEN}help${NC}              Mostrar esta ayuda

${CYAN}Comandos avanzados:${NC}
  ${GREEN}auth${NC}              Tests especÃ­ficos de autenticaciÃ³n JWT
  ${GREEN}failed${NC}             Mostrar solo tests que fallan
  ${GREEN}coverage${NC}          Tests con reporte de cobertura HTML
  ${GREEN}parallel${NC}          Ejecutar tests en paralelo
  ${GREEN}fast${NC}              Tests rÃ¡pidos sin slow tests
  ${GREEN}clean${NC}             Limpiar cachÃ© y archivos temporales

${CYAN}MÃ³dulos disponibles:${NC}

EOF
    list_modules
    
    cat << EOF
${CYAN}Ejemplos de uso rÃ¡pido:${NC}
  $0                     # Resumen ejecutivo (por defecto)
  $0 all                 # Todos los 152 tests
  $0 summary             # Resumen rÃ¡pido
  $0 users               # Tests del mÃ³dulo usuarios
  $0 report              # Reporte detallado
  $0 auth                # Tests de autenticaciÃ³n
  $0 coverage            # Con cobertura de cÃ³digo

${CYAN}Nuevas caracterÃ­sticas (v2.0):${NC}
  âœ“ ValidaciÃ³n de autenticaciÃ³n JWT
  âœ“ Tests de control de acceso por roles
  âœ“ Resumen ejecutivo rÃ¡pido (por defecto)
  âœ“ Filtrado de fallos
  âœ“ 152 tests de integraciÃ³n completos

${CYAN}InformaciÃ³n importante:${NC}
  â€¢ Este script prueba 152 tests de integraciÃ³n
  â€¢ Incluye validaciÃ³n de autenticaciÃ³n JWT
  â€¢ Verifica control de acceso basado en roles (RBAC)
  â€¢ Requiere pytest y entorno virtual activado
  
${CYAN}Estado actual:${NC}
  âœ“ AutenticaciÃ³n: ACTIVA
  âœ“ Roles: ADMINISTRADOR, SUPERVISOR, EMPLEADO
  âœ“ Coverage: 152/152 tests
  
${CYAN}Requisitos:${NC}
  - Python 3.9+
  - Entorno virtual: source venv/bin/activate
  - Dependencias: pip install -r requirements.txt

EOF
}

# Mostrar ayuda


# ============================================================================
# MAIN
# ============================================================================

main() {
    check_venv
    
    local command=${1:-summary}
    
    case "$command" in
        all)
            run_all_tests
            ;;
        coverage)
            run_with_coverage
            ;;
        report)
            show_status_report
            ;;
        summary)
            show_quick_summary
            ;;
        fast)
            run_fast_tests
            ;;
        parallel)
            run_parallel_tests
            ;;
        auth)
            run_auth_tests
            ;;
        failed)
            show_failed_only
            ;;
        clean)
            clean_cache
            ;;
        list)
            list_modules
            ;;
        help|--help|-h)
            show_help
            ;;
        *)
            # Asumir que es un nombre de mÃ³dulo
            run_module_tests "$command"
            ;;
    esac
}

# Ejecutar main con argumentos
main "$@"
