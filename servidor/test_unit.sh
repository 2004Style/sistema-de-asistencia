#!/bin/bash

# ============================================================================
# TEST UNITARIO - Sistema de Asistencia
# Script unificado para ejecutar pruebas unitarias
# ============================================================================
# Uso: ./test_unit.sh [comando] [opciones]
# Comandos disponibles:
#   all         - Ejecutar todos los tests unitarios
#   <servicio>  - Ejecutar tests de un servicio especÃ­fico
#   coverage    - Ejecutar tests con reporte de cobertura
#   report      - Mostrar reporte de status por servicio
#   fast        - Ejecutar solo tests rÃ¡pidos
#   parallel    - Ejecutar tests en paralelo
#   clean       - Limpiar cachÃ©
#   help        - Mostrar esta ayuda
# ============================================================================

set -e

SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
PROJECT_ROOT="$SCRIPT_DIR"

# Colores ANSI
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
MAGENTA='\033[0;35m'
WHITE='\033[1;37m'
NC='\033[0m' # No Color

# ============================================================================
# FUNCIONES DE UTILIDAD
# ============================================================================

print_header() {
    echo ""
    echo -e "${BLUE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${BLUE}â•‘${NC} $1"
    echo -e "${BLUE}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
}

print_section() {
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${CYAN}$1${NC}"
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
}

print_success() {
    echo -e "${GREEN}âœ“ $1${NC}"
}

print_error() {
    echo -e "${RED}âœ— $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš  $1${NC}"
}

print_info() {
    echo -e "${MAGENTA}â„¹ $1${NC}"
}

# Verificar que pytest estÃ© instalado
check_pytest() {
    if ! python -m pip show pytest > /dev/null 2>&1; then
        print_error "pytest no estÃ¡ instalado"
        echo "Ejecuta: pip install -r requirements.txt"
        exit 1
    fi
}

# Verificar entorno virtual
check_venv() {
    if [ -z "$VIRTUAL_ENV" ]; then
        print_warning "No estÃ¡s en un entorno virtual"
        print_info "Intenta: source venv/bin/activate"
    fi
}

# ============================================================================
# COMANDOS DE PRUEBA
# ============================================================================

# Ejecutar todos los tests unitarios
run_all_tests() {
    print_header "Ejecutando TODOS los tests unitarios"
    check_pytest
    python -m pytest tests/unit/ -v --tb=short --disable-warnings
}

# Ejecutar tests de un servicio especÃ­fico
run_service_tests() {
    local service=$1
    print_header "Ejecutando tests para: ${WHITE}$service${NC}"
    check_pytest
    
    if [ -f "tests/unit/test_${service}_service.py" ]; then
        python -m pytest "tests/unit/test_${service}_service.py" -v --tb=short --disable-warnings
    else
        print_error "No se encontrÃ³ tests/unit/test_${service}_service.py"
        print_info "Servicios disponibles:"
        list_services
        exit 1
    fi
}

# Ejecutar tests con cobertura
run_with_coverage() {
    print_header "Ejecutando tests CON COBERTURA"
    check_pytest
    
    python -m pytest tests/unit/ \
        --cov=src \
        --cov-report=html \
        --cov-report=term-missing \
        --cov-report=xml \
        -v --disable-warnings
    
    print_success "Reporte de cobertura generado en ${CYAN}htmlcov/index.html${NC}"
}

# Ejecutar tests rÃ¡pidos
run_fast_tests() {
    print_header "Ejecutando tests RÃPIDOS"
    check_pytest
    python -m pytest tests/unit/ -v -m "not slow" --disable-warnings
}

# Ejecutar tests en paralelo
run_parallel_tests() {
    print_header "Ejecutando tests EN PARALELO"
    check_pytest
    
    if ! python -m pip show pytest-xdist > /dev/null 2>&1; then
        print_warning "pytest-xdist no estÃ¡ instalado"
        print_info "Instalando pytest-xdist..."
        pip install pytest-xdist
    fi
    
    python -m pytest tests/unit/ -v -n auto --tb=short --disable-warnings
}

# Mostrar reporte de status por servicio (MEJORADO CON DETALLE COMPLETO)
show_status_report() {
    print_header "REPORTE COMPLETO DE TESTS UNITARIOS"
    
    check_pytest
    
    services=("asistencias" "email" "horarios" "justificaciones" "notificaciones" "reportes" "roles" "turnos" "users")
    
    total_passed=0
    total_failed=0
    total_error=0
    total_skipped=0
    declare -A service_details
    declare -A service_time
    
    print_section "EJECUCIÃ“N DE PRUEBAS POR SERVICIO"
    echo ""
    
    # Tabla de encabezado
    printf "%-18s %8s %8s %8s %8s %10s %8s\n" \
        "SERVICIO" "PASSED" "FAILED" "ERROR" "SKIP" "TIEMPO" "ESTADO"
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    
    for service in "${services[@]}"; do
        test_file="tests/unit/test_${service}_service.py"
        
        if [ ! -f "$test_file" ]; then
            printf "%-18s %8s %8s %8s %8s %10s %8s\n" \
                "$service" "-" "-" "-" "-" "-" "${RED}NO EXISTE${NC}"
            continue
        fi
        
        # Ejecutar tests con timing
        start_time=$(date +%s)
        output=$(python -m pytest "$test_file" -v --tb=no --disable-warnings 2>&1)
        end_time=$(date +%s)
        
        # Calcular tiempo en segundos
        elapsed=$((end_time - start_time))
        service_time["$service"]=$elapsed
        
        # Extraer nÃºmeros usando grep
        passed=$(echo "$output" | grep -oP '\d+(?= passed)' | tail -1 || echo "0")
        failed=$(echo "$output" | grep -oP '\d+(?= failed)' | tail -1 || echo "0")
        error=$(echo "$output" | grep -oP '\d+(?= error)' | tail -1 || echo "0")
        skipped=$(echo "$output" | grep -oP '\d+(?= skipped)' | tail -1 || echo "0")
        
        # Asegurar que sean nÃºmeros
        passed=${passed:-0}
        failed=${failed:-0}
        error=${error:-0}
        skipped=${skipped:-0}
        
        total_passed=$((total_passed + passed))
        total_failed=$((total_failed + failed))
        total_error=$((total_error + error))
        total_skipped=$((total_skipped + skipped))
        
        # Guardar detalles
        service_details["$service"]="$passed|$failed|$error|$skipped"
        
        # Determinar estado
        if [ "$failed" -eq 0 ] && [ "$error" -eq 0 ]; then
            status="${GREEN}âœ“ OK${NC}"
        elif [ "$passed" -gt 0 ]; then
            status="${YELLOW}âš  PARCIAL${NC}"
        else
            status="${RED}âœ— FALLO${NC}"
        fi
        
        # Formatear fila de tabla
        printf "%-18s %8d %8d %8d %8d %9ds %8b\n" \
            "$service" "$passed" "$failed" "$error" "$skipped" "$elapsed" "$status"
    done
    
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    
    # Totales
    total_tests=$((total_passed + total_failed + total_error))
    if [ "$total_skipped" -gt 0 ]; then
        total_tests=$((total_tests + total_skipped))
    fi
    
    printf "%-18s %8d %8d %8d %8d %9s\n" \
        "${WHITE}TOTAL${NC}" "$total_passed" "$total_failed" "$total_error" "$total_skipped" "â”€â”€â”€â”€â”€â”€"
    
    echo ""
    print_section "RESUMEN Y ANÃLISIS"
    echo ""
    
    # CÃ¡lculos
    if [ "$total_tests" -gt 0 ]; then
        percentage=$((total_passed * 100 / total_tests))
        effectiveness=$((total_passed * 100 / (total_passed + total_failed + total_error)))
    else
        percentage=0
        effectiveness=0
    fi
    
    # InformaciÃ³n detallada
    cat << EOF
  ğŸ“Š ESTADÃSTICAS GENERALES
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total de Tests:            ${WHITE}$total_tests${NC}
  âœ“ Exitosos:                ${GREEN}$total_passed${NC}
  âœ— Fallidos:                ${RED}$total_failed${NC}
  âš  Errores:                 ${RED}$total_error${NC}
  âŠ˜ Saltados:                ${YELLOW}$total_skipped${NC}
  
  ğŸ“ˆ MÃ‰TRICAS DE CALIDAD
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Tasa de Ã‰xito:             $percentage%
  Cobertura Efectiva:        $effectiveness%
  
  ğŸ¯ RESULTADO FINAL
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EOF
    
    if [ "$percentage" -eq 100 ] && [ "$total_failed" -eq 0 ] && [ "$total_error" -eq 0 ]; then
        echo -e "  ${GREEN}âœ“ TODAS LAS PRUEBAS PASARON EXITOSAMENTE${NC}"
    elif [ "$percentage" -ge 90 ]; then
        echo -e "  ${GREEN}âœ“ EXCELENTE - La mayorÃ­a de pruebas pasaron${NC}"
    elif [ "$percentage" -ge 80 ]; then
        echo -e "  ${YELLOW}âš  BUENO - Hay algunos problemas menores${NC}"
    elif [ "$percentage" -ge 50 ]; then
        echo -e "  ${YELLOW}âš  ACEPTABLE - Revisar pruebas fallidas${NC}"
    else
        echo -e "  ${RED}âœ— CRÃTICO - MÃºltiples fallos detectados${NC}"
    fi
    
    echo ""
    print_section "DETALLES POR SERVICIO"
    echo ""
    
    for service in "${services[@]}"; do
        if [ -z "${service_details[$service]}" ]; then
            continue
        fi
        
        IFS='|' read -r passed failed error skipped <<< "${service_details[$service]}"
        elapsed="${service_time[$service]}"
        
        total_service=$((passed + failed + error))
        
        # Determinar estado
        if [ "$failed" -eq 0 ] && [ "$error" -eq 0 ]; then
            status="${GREEN}EXITOSO${NC}"
            icon="âœ“"
        elif [ "$passed" -gt 0 ]; then
            status="${YELLOW}PARCIAL${NC}"
            icon="âš "
        else
            status="${RED}FALLIDO${NC}"
            icon="âœ—"
        fi
        
        echo -e "$icon ${WHITE}$service${NC} ($status)"
        echo -e "   Pasadas: ${GREEN}$passed/$total_service${NC} | Tiempo: ${CYAN}${elapsed}s${NC}"
        
        if [ "$failed" -gt 0 ] || [ "$error" -gt 0 ]; then
            echo -e "   ${RED}Problemas: $failed fallidas, $error errores${NC}"
        fi
        echo ""
    done
    
    echo ""
}

# Limpiar cachÃ©
clean_cache() {
    print_header "Limpiando cachÃ© y archivos temporales"
    
    echo -e "${CYAN}Eliminando directorios __pycache__...${NC}"
    find . -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
    
    echo -e "${CYAN}Eliminando archivos .pyc...${NC}"
    find . -type f -name "*.pyc" -delete 2>/dev/null || true
    
    echo -e "${CYAN}Eliminando cachÃ© de pytest...${NC}"
    rm -rf .pytest_cache htmlcov .coverage .coverage.* 2>/dev/null || true
    
    print_success "CachÃ© limpiado"
}

# Listar servicios disponibles
list_services() {
    echo ""
    for file in tests/unit/test_*_service.py; do
        if [ -f "$file" ]; then
            service=$(basename "$file" | sed 's/test_//;s/_service.py//')
            echo "  - $service"
        fi
    done
    echo ""
}

# Mostrar ayuda
show_help() {
    cat << EOF

${WHITE}Test Unitario - Sistema de Asistencia${NC}
VersiÃ³n: 1.0

${CYAN}Uso:${NC}
  $0 [comando] [opciones]

${CYAN}Comandos:${NC}
  ${GREEN}all${NC}              Ejecutar TODOS los tests unitarios
  ${GREEN}<servicio>${NC}        Ejecutar tests de un servicio especÃ­fico
                        Ejemplo: $0 roles
  ${GREEN}coverage${NC}          Ejecutar tests con reporte de cobertura HTML
  ${GREEN}report${NC}            Mostrar reporte de status por servicio
  ${GREEN}fast${NC}              Ejecutar solo tests rÃ¡pidos (sin slow)
  ${GREEN}parallel${NC}          Ejecutar tests en paralelo para mÃ¡s rapidez
  ${GREEN}clean${NC}             Limpiar cachÃ© y archivos temporales
  ${GREEN}help${NC}              Mostrar esta ayuda

${CYAN}Servicios disponibles:${NC}

EOF
    list_services
    
    cat << EOF
${CYAN}Ejemplos de uso:${NC}
  $0 all                    # Ejecutar todos los tests
  $0 roles                  # Tests del servicio de roles
  $0 users                  # Tests del servicio de usuarios
  $0 coverage               # Tests con reporte de cobertura
  $0 report                 # Reporte de status
  $0 parallel               # Tests en paralelo
  $0 clean                  # Limpiar cachÃ©

${CYAN}Requisitos:${NC}
  - Python 3.9+
  - Entorno virtual activado
  - pytest instalado (pip install -r requirements.txt)

${CYAN}Nota:${NC}
  Este script requiere estar en un entorno virtual activado.
  Si no estÃ¡s en uno, ejecuta primero:
    source venv/bin/activate

EOF
}

# ============================================================================
# MAIN
# ============================================================================

main() {
    check_venv
    
    local command=${1:-help}
    
    case "$command" in
        all)
            run_all_tests
            ;;
        coverage)
            run_with_coverage
            ;;
        report)
            show_status_report
            ;;
        fast)
            run_fast_tests
            ;;
        parallel)
            run_parallel_tests
            ;;
        clean)
            clean_cache
            ;;
        list)
            list_services
            ;;
        help|--help|-h)
            show_help
            ;;
        *)
            # Asumir que es un nombre de servicio
            run_service_tests "$command"
            ;;
    esac
}

# Ejecutar main con argumentos
main "$@"
